{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2. DATA PREPARATION FOR MMSBM (discretizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models we'll create (always using a SVC)... D-> discretized / ND-> non discretized:\n",
    "- a) Genes D (T=5)\n",
    "- b) Genes D (T=5)\n",
    "- c) Genes ND\n",
    "\n",
    "\n",
    "- d) Cells D (T=6)\n",
    "- e) Cells D (T=7)\n",
    "- f) Cells ND\n",
    "\n",
    "\n",
    "- g) Genes D (5) + Cells D (6)\n",
    "- h) Genes ND + Cells ND\n",
    "\n",
    "\n",
    "- i) Genes D (5) + Cells D (6) + dosage (type, time, dose)\n",
    "- j) Genes ND + Cells ND + dosage (same as the original dataset, we'll use the one already created)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv(\"../lish-moa/train_features.csv\", index_col=0)\n",
    "targets = pd.read_csv(\"../lish-moa/train_targets_scored.csv\", index_col=0)\n",
    "#cp_type:\n",
    "features.loc[features.cp_type == \"trt_cp\", \"cp_type\"] = 0\n",
    "features.loc[features.cp_type == \"ctl_vehicle\", \"cp_type\"] = 1 #CONTROL = 1\n",
    "#cp_dose:\n",
    "features.loc[features.cp_dose == \"D1\", 'cp_dose'] = 0\n",
    "features.loc[features.cp_dose == \"D2\", 'cp_dose'] = 1\n",
    "\n",
    "\n",
    "# Data to be used for the model:\n",
    "xtrain = pd.read_csv(\"xtrain.csv\", index_col=0)\n",
    "ytrain = pd.read_csv(\"ytrain.csv\", index_col=0)\n",
    "\n",
    "# Data to be used for the predictions:\n",
    "xtest = pd.read_csv(\"xtest.csv\", index_col=0)\n",
    "ytest = pd.read_csv(\"ytest.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "772"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many genes do we have?\n",
    "g_columns = [g for g in features.columns.tolist() if g.startswith('g-')]\n",
    "len(g_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many cell lines?\n",
    "c_columns = [c for c in features.columns.tolist() if c.startswith('c-')]\n",
    "len(c_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = pd.read_csv(\"Z-scores_features_over_control.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. GENE discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we thought there would be more differences between these distributions and the ones we had by calculating the zscores using the mean and standar deviation of all the samples (treated and control)!!!, let's now try to find a threshold (T) so that we can discretize the gene expression. \n",
    "\n",
    "Instead of having a number which represents this expression, we want to have 3 different \"classes\":\n",
    "- Underexpressed (z-score < -T) &rarr; -1\n",
    "- Normal (-T ≥ z-score ≤ +T)    &rarr; 0\n",
    "- Overexpressed (z-score > +T)  &rarr; 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) T=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must discretize both the training set and the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_discretization(names_cols, z_scores, threshold):\n",
    "    new_df = pd.DataFrame(index = z_scores.index, columns = names_cols)\n",
    "    for element in names_cols:\n",
    "        new_column = []\n",
    "        for i in range(z_scores.shape[0]):\n",
    "            if (z_scores[element][i] < -threshold):\n",
    "                new_column.append(-1)\n",
    "            elif (z_scores[element][i] > threshold):\n",
    "                new_column.append(1)\n",
    "            else:\n",
    "                new_column.append(0)\n",
    "        new_df[element] = new_column        \n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_discretized = gene_discretization(g_columns, z_scores, 5)\n",
    "genes_discretized.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New data -> New model\n",
    "Let's create a model (SVC for example) with this new data. We're just taking into consideration the genes, leaving cell viability and dosage data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultipleColumns_model(xtrain, ytrain, c, estimator):\n",
    "    \"\"\"Torna una llista amb els models creats i adaptats per a cada columna.\n",
    "        Entrades: ytrain i número de columnes que agafem.\n",
    "    \"\"\"\n",
    "    models = [] #llista dels models per a cada columna\n",
    "    for i in range(c): #from 0 to number of columns\n",
    "        models.append(estimator(probability = True)) #Prob = True bc we want to predict_proba\n",
    "        models[i].fit(xtrain, ytrain.iloc[:,i]) #Fitting the model with all xtrain and 1 column of ytrain\n",
    "        print(\"model\", i, \"done\")\n",
    "    return models\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data used for the model:\n",
    "xtrain = genes_discretized.loc[xtrain.index.tolist(), :].copy()\n",
    "#xtrain = xtrain.drop('cp_type', axis=1)\n",
    "ytrain = targets.loc[xtrain.index.tolist(), :].copy()\n",
    "\n",
    "# Data used for the predictions:\n",
    "xtest = genes_discretized.loc[xtest.index.tolist(), :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = MultipleColumns_model(xtrain, ytrain, ytrain.shape[1], SVC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(svc_model, 'output/7a_model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe for saving the predictions\n",
    "proba_pred_SVC = pd.DataFrame(columns=ytest.columns)\n",
    "\n",
    "name_col = ytest.columns.tolist()\n",
    "for i in range(ytest.shape[1]): \n",
    "    proba_pred_SVC[name_col[i]] = svc_model[i].predict_proba(xtest)[:, 1]\n",
    "    print(i, end=' ', flush=True)\n",
    "    \n",
    "proba_pred_SVC[\"sig_id\"]= xtest.index.tolist()\n",
    "proba_pred_SVC = proba_pred_SVC.set_index('sig_id')\n",
    "proba_pred_SVC.to_csv('output/7a_probas.csv')\n",
    "proba_pred_SVC.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) T=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_discretized = gene_discretization(g_columns, z_scores, 6)\n",
    "\n",
    "# Data used for the model:\n",
    "xtrain = genes_discretized.loc[xtrain.index.tolist(), :].copy()\n",
    "ytrain = targets.loc[xtrain.index.tolist(), :].copy()\n",
    "# Data used for the predictions:\n",
    "xtest = genes_discretized.loc[xtest.index.tolist(), :].copy()\n",
    "\n",
    "svc_model = MultipleColumns_model(xtrain, ytrain, ytrain.shape[1], SVC) \n",
    "dump(svc_model, 'output/7b_model.joblib') \n",
    "\n",
    "#new dataframe for saving the predictions\n",
    "proba_pred_SVC = pd.DataFrame(columns=ytest.columns)\n",
    "\n",
    "name_col = ytest.columns.tolist()\n",
    "for i in range(ytest.shape[1]): \n",
    "    proba_pred_SVC[name_col[i]] = svc_model[i].predict_proba(xtest)[:, 1]\n",
    "    print(i, end=' ', flush=True)\n",
    "    \n",
    "proba_pred_SVC[\"sig_id\"]= xtest.index.tolist()\n",
    "proba_pred_SVC = proba_pred_SVC.set_index('sig_id')\n",
    "proba_pred_SVC.to_csv('output/7b_probas.csv')\n",
    "proba_pred_SVC.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________\n",
    "## 7.2. CELL discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having a number which represents this viability, we want to have 2 different \"classes\":\n",
    "- Non-viable (z-score < -T) &rarr; 0\n",
    "- Viable (z-score ≤ T)    &rarr; 1\n",
    "\n",
    "We'll only look for those samples in which a surprising number of cells have died, because we think that most of the treatment will tend to reduce the population of some type of cells (we decide so also by looking at the plots obtained in the previous notebook).\n",
    "\n",
    "Potential thresholds: 6 or 7. (Why? Imagine the slope of the control distributions... where does it reaches the x axis?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_discretization(names_cols, z_scores, threshold):\n",
    "    new_df = pd.DataFrame(index = z_scores.index, columns = names_cols)\n",
    "    for element in names_cols:\n",
    "        new_column = []\n",
    "        for i in range(z_scores.shape[0]):\n",
    "            if (z_scores[element][i] < -threshold):\n",
    "                new_column.append(0)\n",
    "            else:\n",
    "                new_column.append(1)\n",
    "        new_df[element] = new_column        \n",
    "    return(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) T = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_discretized = cell_discretization(c_columns, z_scores, 6)\n",
    "cells_discretized_6.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data used for the model:\n",
    "xtrain = cells_discretized.loc[xtrain.index.tolist(), :].copy()\n",
    "ytrain = targets.loc[xtrain.index.tolist(), :].copy()\n",
    "# Data used for the predictions:\n",
    "xtest = cells_discretized.loc[xtest.index.tolist(), :].copy()\n",
    "\n",
    "svc_model = MultipleColumns_model(xtrain, ytrain, ytrain.shape[1], SVC) \n",
    "dump(svc_model, 'output/7e_model.joblib') \n",
    "\n",
    "#new dataframe for saving the predictions\n",
    "proba_pred_SVC = pd.DataFrame(columns=ytest.columns)\n",
    "\n",
    "name_col = ytest.columns.tolist()\n",
    "for i in range(ytest.shape[1]): \n",
    "    proba_pred_SVC[name_col[i]] = svc_model[i].predict_proba(xtest)[:, 1]\n",
    "    print(i, end=' ', flush=True)\n",
    "    \n",
    "proba_pred_SVC[\"sig_id\"]= xtest.index.tolist()\n",
    "proba_pred_SVC = proba_pred_SVC.set_index('sig_id')\n",
    "proba_pred_SVC.to_csv('output/7e_probas.csv')\n",
    "proba_pred_SVC.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) T = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_discretized = cell_discretization(c_columns, z_scores, 7)\n",
    "\n",
    "# Data used for the model:\n",
    "xtrain = cells_discretized.loc[xtrain.index.tolist(), :].copy()\n",
    "ytrain = targets.loc[xtrain.index.tolist(), :].copy()\n",
    "# Data used for the predictions:\n",
    "xtest = cells_discretized.loc[xtest.index.tolist(), :].copy()\n",
    "\n",
    "svc_model = MultipleColumns_model(xtrain, ytrain, ytrain.shape[1], SVC) \n",
    "dump(svc_model, 'output/7f_model.joblib') \n",
    "\n",
    "#new dataframe for saving the predictions\n",
    "proba_pred_SVC = pd.DataFrame(columns=ytest.columns)\n",
    "\n",
    "name_col = ytest.columns.tolist()\n",
    "for i in range(ytest.shape[1]): \n",
    "    proba_pred_SVC[name_col[i]] = svc_model[i].predict_proba(xtest)[:, 1]\n",
    "    print(i, end=' ', flush=True)\n",
    "    \n",
    "proba_pred_SVC[\"sig_id\"]= xtest.index.tolist()\n",
    "proba_pred_SVC = proba_pred_SVC.set_index('sig_id')\n",
    "proba_pred_SVC.to_csv('output/7f_probas.csv')\n",
    "proba_pred_SVC.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "In order to understand the reasons of an improvement (or a deterioration) of the log loss score, we need to create different models (taking into account only genes without discretization, only cells without discretization and so on).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Genes ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = 'genes'                                                                                                            \n",
    "\n",
    "features = pd.read_csv(\"../lish-moa/train_features.csv\", index_col=0)\n",
    "targets = pd.read_csv(\"../lish-moa/train_targets_scored.csv\", index_col=0)\n",
    "#cp_type:                                                                                                                                        \n",
    "features.loc[features.cp_type == \"trt_cp\", \"cp_type\"] = 0\n",
    "features.loc[features.cp_type == \"ctl_vehicle\", \"cp_type\"] = 1 #CONTROL = 1                                                                      \n",
    "#cp_dose:                                                                                                                                        \n",
    "features.loc[features.cp_dose == \"D1\", 'cp_dose'] = 0\n",
    "features.loc[features.cp_dose == \"D2\", 'cp_dose'] = 1\n",
    "# Data to be used for the model:                                                                                                                 \n",
    "xtrain = pd.read_csv(\"xtrain.csv\", index_col=0)\n",
    "ytrain = pd.read_csv(\"ytrain.csv\", index_col=0)\n",
    "# Data to be used for the predictions:                                                                                                           \n",
    "xtest = pd.read_csv(\"xtest.csv\", index_col=0)\n",
    "ytest = pd.read_csv(\"ytest.csv\", index_col=0)\n",
    "g_columns = [g for g in features.columns.tolist() if g.startswith('g-')]\n",
    "c_columns = [c for c in features.columns.tolist() if c.startswith('c-')]\n",
    "\n",
    "if what=='genes':\n",
    "    discretized = features.loc[:,g_columns].copy()\n",
    "if what=='cells':\n",
    "    discretized = features.loc[:,c_columns].copy()\n",
    "if what=='both': \n",
    "    discretized = features.loc[:,g_columns+c_columns].copy()\n",
    "    \n",
    "# Data used for the model:                                                                                                                       \n",
    "xtrain = discretized.loc[xtrain.index.tolist(), :].copy()\n",
    "#xtrain = xtrain.drop('cp_type', axis=1)                                                                                                         \n",
    "ytrain = targets.loc[xtrain.index.tolist(), :].copy() #remains the same                                                                          \n",
    "# Data used for the predictions:                                                                                                                 \n",
    "xtest = discretized.loc[xtest.index.tolist(), :].copy()\n",
    "svc_model = MultipleColumns_model(xtrain, ytrain, ytrain.shape[1], SVC)\n",
    "from joblib import dump\n",
    "dump(svc_model, 'output/7c_model.joblib')\n",
    "#new dataframe for saving the predictions                                                                                                        \n",
    "proba_pred_SVC = pd.DataFrame(columns=ytest.columns)\n",
    "name_col = ytest.columns.tolist()\n",
    "for i in range(ytest.shape[1]):\n",
    "    proba_pred_SVC[name_col[i]] = svc_model[i].predict_proba(xtest)[:, 1]\n",
    "    print(i, end=' ', flush=True)\n",
    "proba_pred_SVC[\"sig_id\"]= xtest.index.tolist()\n",
    "proba_pred_SVC = proba_pred_SVC.set_index('sig_id')\n",
    "proba_pred_SVC.to_csv('output/7c_probas.csv')                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Cells ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = 'cells'                                                                                                            \n",
    "\n",
    "features = pd.read_csv(\"../lish-moa/train_features.csv\", index_col=0)\n",
    "targets = pd.read_csv(\"../lish-moa/train_targets_scored.csv\", index_col=0)\n",
    "#cp_type:                                                                                                                                        \n",
    "features.loc[features.cp_type == \"trt_cp\", \"cp_type\"] = 0\n",
    "features.loc[features.cp_type == \"ctl_vehicle\", \"cp_type\"] = 1 #CONTROL = 1                                                                      \n",
    "#cp_dose:                                                                                                                                        \n",
    "features.loc[features.cp_dose == \"D1\", 'cp_dose'] = 0\n",
    "features.loc[features.cp_dose == \"D2\", 'cp_dose'] = 1\n",
    "# Data to be used for the model:                                                                                                                 \n",
    "xtrain = pd.read_csv(\"xtrain.csv\", index_col=0)\n",
    "ytrain = pd.read_csv(\"ytrain.csv\", index_col=0)\n",
    "# Data to be used for the predictions:                                                                                                           \n",
    "xtest = pd.read_csv(\"xtest.csv\", index_col=0)\n",
    "ytest = pd.read_csv(\"ytest.csv\", index_col=0)\n",
    "g_columns = [g for g in features.columns.tolist() if g.startswith('g-')]\n",
    "c_columns = [c for c in features.columns.tolist() if c.startswith('c-')]\n",
    "\n",
    "if what=='genes':\n",
    "    discretized = features.loc[:,g_columns].copy()\n",
    "if what=='cells':\n",
    "    discretized = features.loc[:,c_columns].copy()\n",
    "if what=='both': \n",
    "    discretized = features.loc[:,g_columns+c_columns].copy()\n",
    "    \n",
    "# Data used for the model:                                                                                                                       \n",
    "xtrain = discretized.loc[xtrain.index.tolist(), :].copy()\n",
    "#xtrain = xtrain.drop('cp_type', axis=1)                                                                                                         \n",
    "ytrain = targets.loc[xtrain.index.tolist(), :].copy() #remains the same                                                                          \n",
    "# Data used for the predictions:                                                                                                                 \n",
    "xtest = discretized.loc[xtest.index.tolist(), :].copy()\n",
    "svc_model = MultipleColumns_model(xtrain, ytrain, ytrain.shape[1], SVC)\n",
    "from joblib import dump\n",
    "dump(svc_model, 'output/7f_model.joblib')\n",
    "#new dataframe for saving the predictions                                                                                                        \n",
    "proba_pred_SVC = pd.DataFrame(columns=ytest.columns)\n",
    "name_col = ytest.columns.tolist()\n",
    "for i in range(ytest.shape[1]):\n",
    "    proba_pred_SVC[name_col[i]] = svc_model[i].predict_proba(xtest)[:, 1]\n",
    "    print(i, end=' ', flush=True)\n",
    "proba_pred_SVC[\"sig_id\"]= xtest.index.tolist()\n",
    "proba_pred_SVC = proba_pred_SVC.set_index('sig_id')\n",
    "proba_pred_SVC.to_csv('output/7f_probas.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h) Genes ND + Cells ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what = 'both'                                                                                                            \n",
    "\n",
    "features = pd.read_csv(\"../lish-moa/train_features.csv\", index_col=0)\n",
    "targets = pd.read_csv(\"../lish-moa/train_targets_scored.csv\", index_col=0)\n",
    "#cp_type:                                                                                                                                        \n",
    "features.loc[features.cp_type == \"trt_cp\", \"cp_type\"] = 0\n",
    "features.loc[features.cp_type == \"ctl_vehicle\", \"cp_type\"] = 1 #CONTROL = 1                                                                      \n",
    "#cp_dose:                                                                                                                                        \n",
    "features.loc[features.cp_dose == \"D1\", 'cp_dose'] = 0\n",
    "features.loc[features.cp_dose == \"D2\", 'cp_dose'] = 1\n",
    "# Data to be used for the model:                                                                                                                 \n",
    "xtrain = pd.read_csv(\"xtrain.csv\", index_col=0)\n",
    "ytrain = pd.read_csv(\"ytrain.csv\", index_col=0)\n",
    "# Data to be used for the predictions:                                                                                                           \n",
    "xtest = pd.read_csv(\"xtest.csv\", index_col=0)\n",
    "ytest = pd.read_csv(\"ytest.csv\", index_col=0)\n",
    "g_columns = [g for g in features.columns.tolist() if g.startswith('g-')]\n",
    "c_columns = [c for c in features.columns.tolist() if c.startswith('c-')]\n",
    "\n",
    "if what=='genes':\n",
    "    discretized = features.loc[:,g_columns].copy()\n",
    "if what=='cells':\n",
    "    discretized = features.loc[:,c_columns].copy()\n",
    "if what=='both': \n",
    "    discretized = features.loc[:,g_columns+c_columns].copy()\n",
    "    \n",
    "# Data used for the model:                                                                                                                       \n",
    "xtrain = discretized.loc[xtrain.index.tolist(), :].copy()\n",
    "#xtrain = xtrain.drop('cp_type', axis=1)                                                                                                         \n",
    "ytrain = targets.loc[xtrain.index.tolist(), :].copy() #remains the same                                                                          \n",
    "# Data used for the predictions:                                                                                                                 \n",
    "xtest = discretized.loc[xtest.index.tolist(), :].copy()\n",
    "svc_model = MultipleColumns_model(xtrain, ytrain, ytrain.shape[1], SVC)\n",
    "from joblib import dump\n",
    "dump(svc_model, 'output/7h_model.joblib')\n",
    "#new dataframe for saving the predictions                                                                                                        \n",
    "proba_pred_SVC = pd.DataFrame(columns=ytest.columns)\n",
    "name_col = ytest.columns.tolist()\n",
    "for i in range(ytest.shape[1]):\n",
    "    proba_pred_SVC[name_col[i]] = svc_model[i].predict_proba(xtest)[:, 1]\n",
    "    print(i, end=' ', flush=True)\n",
    "proba_pred_SVC[\"sig_id\"]= xtest.index.tolist()\n",
    "proba_pred_SVC = proba_pred_SVC.set_index('sig_id')\n",
    "proba_pred_SVC.to_csv('output/7h_probas.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Genes T=5 + Cells T=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 done\n",
      "model 1 done\n",
      "model 2 done\n",
      "model 3 done\n",
      "model 4 done\n",
      "model 5 done\n",
      "model 6 done\n",
      "model 7 done\n",
      "model 8 done\n",
      "model 9 done\n",
      "model 10 done\n",
      "model 11 done\n",
      "model 12 done\n",
      "model 13 done\n",
      "model 14 done\n",
      "model 15 done\n",
      "model 16 done\n",
      "model 17 done\n",
      "model 18 done\n",
      "model 19 done\n",
      "model 20 done\n",
      "model 21 done\n",
      "model 22 done\n",
      "model 23 done\n",
      "model 24 done\n",
      "model 25 done\n",
      "model 26 done\n",
      "model 27 done\n",
      "model 28 done\n",
      "model 29 done\n",
      "model 30 done\n",
      "model 31 done\n",
      "model 32 done\n",
      "model 33 done\n",
      "model 34 done\n",
      "model 35 done\n",
      "model 36 done\n",
      "model 37 done\n",
      "model 38 done\n",
      "model 39 done\n",
      "model 40 done\n",
      "model 41 done\n",
      "model 42 done\n",
      "model 43 done\n",
      "model 44 done\n",
      "model 45 done\n",
      "model 46 done\n",
      "model 47 done\n",
      "model 48 done\n",
      "model 49 done\n",
      "model 50 done\n",
      "model 51 done\n",
      "model 52 done\n",
      "model 53 done\n",
      "model 54 done\n",
      "model 55 done\n",
      "model 56 done\n",
      "model 57 done\n",
      "model 58 done\n",
      "model 59 done\n",
      "model 60 done\n",
      "model 61 done\n",
      "model 62 done\n",
      "model 63 done\n",
      "model 64 done\n",
      "model 65 done\n",
      "model 66 done\n",
      "model 67 done\n",
      "model 68 done\n",
      "model 69 done\n",
      "model 70 done\n",
      "model 71 done\n",
      "model 72 done\n",
      "model 73 done\n",
      "model 74 done\n",
      "model 75 done\n",
      "model 76 done\n",
      "model 77 done\n",
      "model 78 done\n",
      "model 79 done\n",
      "model 80 done\n",
      "model 81 done\n",
      "model 82 done\n",
      "model 83 done\n",
      "model 84 done\n",
      "model 85 done\n",
      "model 86 done\n",
      "model 87 done\n",
      "model 88 done\n",
      "model 89 done\n",
      "model 90 done\n",
      "model 91 done\n",
      "model 92 done\n",
      "model 93 done\n",
      "model 94 done\n",
      "model 95 done\n",
      "model 96 done\n",
      "model 97 done\n",
      "model 98 done\n",
      "model 99 done\n",
      "model 100 done\n",
      "model 101 done\n",
      "model 102 done\n",
      "model 103 done\n",
      "model 104 done\n",
      "model 105 done\n",
      "model 106 done\n",
      "model 107 done\n",
      "model 108 done\n",
      "model 109 done\n",
      "model 110 done\n",
      "model 111 done\n",
      "model 112 done\n",
      "model 113 done\n",
      "model 114 done\n",
      "model 115 done\n",
      "model 116 done\n",
      "model 117 done\n",
      "model 118 done\n",
      "model 119 done\n",
      "model 120 done\n",
      "model 121 done\n",
      "model 122 done\n",
      "model 123 done\n",
      "model 124 done\n",
      "model 125 done\n",
      "model 126 done\n",
      "model 127 done\n",
      "model 128 done\n",
      "model 129 done\n",
      "model 130 done\n",
      "model 131 done\n",
      "model 132 done\n",
      "model 133 done\n",
      "model 134 done\n",
      "model 135 done\n",
      "model 136 done\n",
      "model 137 done\n",
      "model 138 done\n",
      "model 139 done\n",
      "model 140 done\n",
      "model 141 done\n",
      "model 142 done\n",
      "model 143 done\n",
      "model 144 done\n",
      "model 145 done\n",
      "model 146 done\n",
      "model 147 done\n",
      "model 148 done\n",
      "model 149 done\n",
      "model 150 done\n",
      "model 151 done\n",
      "model 152 done\n",
      "model 153 done\n",
      "model 154 done\n",
      "model 155 done\n",
      "model 156 done\n",
      "model 157 done\n",
      "model 158 done\n",
      "model 159 done\n",
      "model 160 done\n",
      "model 161 done\n",
      "model 162 done\n",
      "model 163 done\n",
      "model 164 done\n",
      "model 165 done\n",
      "model 166 done\n",
      "model 167 done\n",
      "model 168 done\n",
      "model 169 done\n",
      "model 170 done\n",
      "model 171 done\n",
      "model 172 done\n",
      "model 173 done\n",
      "model 174 done\n",
      "model 175 done\n",
      "model 176 done\n",
      "model 177 done\n",
      "model 178 done\n",
      "model 179 done\n",
      "model 180 done\n",
      "model 181 done\n",
      "model 182 done\n",
      "model 183 done\n",
      "model 184 done\n",
      "model 185 done\n",
      "model 186 done\n",
      "model 187 done\n",
      "model 188 done\n",
      "model 189 done\n",
      "model 190 done\n",
      "model 191 done\n",
      "model 192 done\n",
      "model 193 done\n",
      "model 194 done\n",
      "model 195 done\n",
      "model 196 done\n",
      "model 197 done\n",
      "model 198 done\n",
      "model 199 done\n",
      "model 200 done\n",
      "model 201 done\n",
      "model 202 done\n",
      "model 203 done\n",
      "model 204 done\n",
      "model 205 done\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "what = 'both' #cells or genes or both                                                                                                             \n",
    "#threshold = int(sys.argv[2])\n",
    "features = pd.read_csv(\"../lish-moa/train_features.csv\", index_col=0)\n",
    "targets = pd.read_csv(\"../lish-moa/train_targets_scored.csv\", index_col=0)\n",
    "#cp_type:                                                                                                                                        \n",
    "features.loc[features.cp_type == \"trt_cp\", \"cp_type\"] = 0\n",
    "features.loc[features.cp_type == \"ctl_vehicle\", \"cp_type\"] = 1 #CONTROL = 1                                                                      \n",
    "#cp_dose:                                                                                                                                        \n",
    "features.loc[features.cp_dose == \"D1\", 'cp_dose'] = 0\n",
    "features.loc[features.cp_dose == \"D2\", 'cp_dose'] = 1\n",
    "# Data to be used for the model:                                                                                                                 \n",
    "xtrain = pd.read_csv(\"xtrain.csv\", index_col=0)\n",
    "ytrain = pd.read_csv(\"ytrain.csv\", index_col=0)\n",
    "# Data to be used for the predictions:                                                                                                           \n",
    "xtest = pd.read_csv(\"xtest.csv\", index_col=0)\n",
    "ytest = pd.read_csv(\"ytest.csv\", index_col=0)\n",
    "z_scores = pd.read_csv(\"Z-scores_features_over_control.csv\", index_col = 0)\n",
    "g_columns = [g for g in features.columns.tolist() if g.startswith('g-')]\n",
    "c_columns = [c for c in features.columns.tolist() if c.startswith('c-')]\n",
    "def gene_discretization(names_cols, z_scores, threshold):\n",
    "    new_df = pd.DataFrame(index = z_scores.index, columns = names_cols)\n",
    "    for element in names_cols:\n",
    "        new_column = []\n",
    "        for i in range(z_scores.shape[0]):\n",
    "            if (z_scores[element][i] < -threshold):\n",
    "                new_column.append(-1)\n",
    "            elif (z_scores[element][i] > threshold):\n",
    "                new_column.append(1)\n",
    "            else:\n",
    "                new_column.append(0)\n",
    "        new_df[element] = new_column\n",
    "    return(new_df)\n",
    "def cell_discretization(names_cols, z_scores, threshold):\n",
    "    new_df = pd.DataFrame(index = z_scores.index, columns = names_cols)\n",
    "    for element in names_cols:\n",
    "        new_column = []\n",
    "        for i in range(z_scores.shape[0]):\n",
    "            if (z_scores[element][i] < -threshold):\n",
    "                new_column.append(0)\n",
    "            else:\n",
    "                new_column.append(1)\n",
    "        new_df[element] = new_column\n",
    "    return(new_df)\n",
    "def MultipleColumns_model(xtrain, ytrain, c, estimator):\n",
    "    \"\"\"Torna una llista amb els models creats i adaptats per a cada columna.                                                                     \n",
    "        Entrades: ytrain i número de columnes que agafem.                                                                                        \n",
    "    \"\"\"\n",
    "    models = [] #llista dels models per a cada columna                                                                                           \n",
    "    for i in range(c): #from 0 to number of columns                                                                                              \n",
    "        models.append(estimator(probability = True)) #Prob = True bc we want to predict_proba                                                    \n",
    "        models[i].fit(xtrain, ytrain.iloc[:,i]) #Fitting the model with all xtrain and 1 column of ytrain                                        \n",
    "        print(\"model\", i, \"done\")\n",
    "    return models\n",
    "from sklearn.svm import SVC\n",
    "if what=='genes':\n",
    "    discretized = gene_discretization(g_columns, z_scores, threshold)\n",
    "if what=='cells':\n",
    "    discretized = cell_discretization(c_columns, z_scores, threshold)\n",
    "if what=='both': discretized=pd.concat([gene_discretization(g_columns,z_scores,5),cell_discretization(c_columns,z_scores,6)],axis=1)\n",
    "# Data used for the model:                                                                                                                       \n",
    "xtrain = discretized.loc[xtrain.index.tolist(), :].copy()\n",
    "#xtrain = xtrain.drop('cp_type', axis=1)                                                                                                         \n",
    "ytrain = targets.loc[xtrain.index.tolist(), :].copy() #remains the same                                                                          \n",
    "# Data used for the predictions:                                                                                                                 \n",
    "xtest = discretized.loc[xtest.index.tolist(), :].copy()\n",
    "svc_model = MultipleColumns_model(xtrain, ytrain, ytrain.shape[1], SVC)\n",
    "from joblib import dump\n",
    "dump(svc_model, 'output/7g_model.joblib')\n",
    "#new dataframe for saving the predictions                                                                                                        \n",
    "proba_pred_SVC = pd.DataFrame(columns=ytest.columns)\n",
    "name_col = ytest.columns.tolist()\n",
    "for i in range(ytest.shape[1]):\n",
    "    proba_pred_SVC[name_col[i]] = svc_model[i].predict_proba(xtest)[:, 1]\n",
    "    print(i, end=' ', flush=True)\n",
    "proba_pred_SVC[\"sig_id\"]= xtest.index.tolist()\n",
    "proba_pred_SVC = proba_pred_SVC.set_index('sig_id')\n",
    "proba_pred_SVC.to_csv('output/7g_probas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Genes T=5 + Cells T=6 + dosage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 done\n",
      "model 1 done\n",
      "model 2 done\n",
      "model 3 done\n",
      "model 4 done\n",
      "model 5 done\n",
      "model 6 done\n",
      "model 7 done\n",
      "model 8 done\n",
      "model 9 done\n",
      "model 10 done\n",
      "model 11 done\n",
      "model 12 done\n",
      "model 13 done\n",
      "model 14 done\n",
      "model 15 done\n",
      "model 16 done\n",
      "model 17 done\n",
      "model 18 done\n",
      "model 19 done\n",
      "model 20 done\n",
      "model 21 done\n",
      "model 22 done\n",
      "model 23 done\n",
      "model 24 done\n",
      "model 25 done\n",
      "model 26 done\n",
      "model 27 done\n",
      "model 28 done\n",
      "model 29 done\n",
      "model 30 done\n",
      "model 31 done\n",
      "model 32 done\n",
      "model 33 done\n",
      "model 34 done\n",
      "model 35 done\n",
      "model 36 done\n",
      "model 37 done\n",
      "model 38 done\n",
      "model 39 done\n",
      "model 40 done\n",
      "model 41 done\n",
      "model 42 done\n",
      "model 43 done\n",
      "model 44 done\n",
      "model 45 done\n",
      "model 46 done\n",
      "model 47 done\n",
      "model 48 done\n",
      "model 49 done\n",
      "model 50 done\n",
      "model 51 done\n",
      "model 52 done\n",
      "model 53 done\n",
      "model 54 done\n",
      "model 55 done\n",
      "model 56 done\n",
      "model 57 done\n",
      "model 58 done\n",
      "model 59 done\n",
      "model 60 done\n",
      "model 61 done\n",
      "model 62 done\n",
      "model 63 done\n",
      "model 64 done\n",
      "model 65 done\n",
      "model 66 done\n",
      "model 67 done\n",
      "model 68 done\n",
      "model 69 done\n",
      "model 70 done\n",
      "model 71 done\n",
      "model 72 done\n",
      "model 73 done\n",
      "model 74 done\n",
      "model 75 done\n",
      "model 76 done\n",
      "model 77 done\n",
      "model 78 done\n",
      "model 79 done\n",
      "model 80 done\n",
      "model 81 done\n",
      "model 82 done\n",
      "model 83 done\n",
      "model 84 done\n",
      "model 85 done\n",
      "model 86 done\n",
      "model 87 done\n",
      "model 88 done\n",
      "model 89 done\n",
      "model 90 done\n",
      "model 91 done\n",
      "model 92 done\n",
      "model 93 done\n",
      "model 94 done\n",
      "model 95 done\n",
      "model 96 done\n",
      "model 97 done\n",
      "model 98 done\n",
      "model 99 done\n",
      "model 100 done\n",
      "model 101 done\n",
      "model 102 done\n",
      "model 103 done\n",
      "model 104 done\n",
      "model 105 done\n",
      "model 106 done\n",
      "model 107 done\n",
      "model 108 done\n",
      "model 109 done\n",
      "model 110 done\n",
      "model 111 done\n",
      "model 112 done\n",
      "model 113 done\n",
      "model 114 done\n",
      "model 115 done\n",
      "model 116 done\n",
      "model 117 done\n",
      "model 118 done\n",
      "model 119 done\n",
      "model 120 done\n",
      "model 121 done\n",
      "model 122 done\n",
      "model 123 done\n",
      "model 124 done\n",
      "model 125 done\n",
      "model 126 done\n",
      "model 127 done\n",
      "model 128 done\n",
      "model 129 done\n",
      "model 130 done\n",
      "model 131 done\n",
      "model 132 done\n",
      "model 133 done\n",
      "model 134 done\n",
      "model 135 done\n",
      "model 136 done\n",
      "model 137 done\n",
      "model 138 done\n",
      "model 139 done\n",
      "model 140 done\n",
      "model 141 done\n",
      "model 142 done\n",
      "model 143 done\n",
      "model 144 done\n",
      "model 145 done\n",
      "model 146 done\n",
      "model 147 done\n",
      "model 148 done\n",
      "model 149 done\n",
      "model 150 done\n",
      "model 151 done\n",
      "model 152 done\n",
      "model 153 done\n",
      "model 154 done\n",
      "model 155 done\n",
      "model 156 done\n",
      "model 157 done\n",
      "model 158 done\n",
      "model 159 done\n",
      "model 160 done\n",
      "model 161 done\n",
      "model 162 done\n",
      "model 163 done\n",
      "model 164 done\n",
      "model 165 done\n",
      "model 166 done\n",
      "model 167 done\n",
      "model 168 done\n",
      "model 169 done\n",
      "model 170 done\n",
      "model 171 done\n",
      "model 172 done\n",
      "model 173 done\n",
      "model 174 done\n",
      "model 175 done\n",
      "model 176 done\n",
      "model 177 done\n",
      "model 178 done\n",
      "model 179 done\n",
      "model 180 done\n",
      "model 181 done\n",
      "model 182 done\n",
      "model 183 done\n",
      "model 184 done\n",
      "model 185 done\n",
      "model 186 done\n",
      "model 187 done\n",
      "model 188 done\n",
      "model 189 done\n",
      "model 190 done\n",
      "model 191 done\n",
      "model 192 done\n",
      "model 193 done\n",
      "model 194 done\n",
      "model 195 done\n",
      "model 196 done\n",
      "model 197 done\n",
      "model 198 done\n",
      "model 199 done\n",
      "model 200 done\n",
      "model 201 done\n",
      "model 202 done\n",
      "model 203 done\n",
      "model 204 done\n",
      "model 205 done\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv(\"../lish-moa/train_features.csv\", index_col=0)\n",
    "targets = pd.read_csv(\"../lish-moa/train_targets_scored.csv\", index_col=0)\n",
    "#cp_type:                                                                                                                                        \n",
    "features.loc[features.cp_type == \"trt_cp\", \"cp_type\"] = 0\n",
    "features.loc[features.cp_type == \"ctl_vehicle\", \"cp_type\"] = 1 #CONTROL = 1                                                                      \n",
    "#cp_dose:                                                                                                                                        \n",
    "features.loc[features.cp_dose == \"D1\", 'cp_dose'] = 0\n",
    "features.loc[features.cp_dose == \"D2\", 'cp_dose'] = 1\n",
    "# Data to be used for the model:                                                                                                                 \n",
    "xtrain = pd.read_csv(\"xtrain.csv\", index_col=0)\n",
    "ytrain = pd.read_csv(\"ytrain.csv\", index_col=0)\n",
    "# Data to be used for the predictions:                                                                                                           \n",
    "xtest = pd.read_csv(\"xtest.csv\", index_col=0)\n",
    "ytest = pd.read_csv(\"ytest.csv\", index_col=0)\n",
    "z_scores = pd.read_csv(\"Z-scores_features_over_control.csv\", index_col = 0)\n",
    "g_columns = [g for g in features.columns.tolist() if g.startswith('g-')]\n",
    "c_columns = [c for c in features.columns.tolist() if c.startswith('c-')]\n",
    "def gene_discretization(names_cols, z_scores, threshold):\n",
    "    new_df = pd.DataFrame(index = z_scores.index, columns = names_cols)\n",
    "    for element in names_cols:\n",
    "        new_column = []\n",
    "        for i in range(z_scores.shape[0]):\n",
    "            if (z_scores[element][i] < -threshold):\n",
    "                new_column.append(-1)\n",
    "            elif (z_scores[element][i] > threshold):\n",
    "                new_column.append(1)\n",
    "            else:\n",
    "                new_column.append(0)\n",
    "        new_df[element] = new_column\n",
    "    return(new_df)\n",
    "def cell_discretization(names_cols, z_scores, threshold):\n",
    "    new_df = pd.DataFrame(index = z_scores.index, columns = names_cols)\n",
    "    for element in names_cols:\n",
    "        new_column = []\n",
    "        for i in range(z_scores.shape[0]):\n",
    "            if (z_scores[element][i] < -threshold):\n",
    "                new_column.append(0)\n",
    "            else:\n",
    "                new_column.append(1)\n",
    "        new_df[element] = new_column\n",
    "    return(new_df)\n",
    "def MultipleColumns_model(xtrain, ytrain, c, estimator):\n",
    "    \"\"\"Torna una llista amb els models creats i adaptats per a cada columna.                                                                     \n",
    "        Entrades: ytrain i número de columnes que agafem.                                                                                        \n",
    "    \"\"\"\n",
    "    models = [] #llista dels models per a cada columna                                                                                           \n",
    "    for i in range(c): #from 0 to number of columns                                                                                              \n",
    "        models.append(estimator(probability = True)) #Prob = True bc we want to predict_proba                                                    \n",
    "        models[i].fit(xtrain, ytrain.iloc[:,i]) #Fitting the model with all xtrain and 1 column of ytrain                                        \n",
    "        print(\"model\", i, \"done\")\n",
    "    return models\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "discretized=pd.concat([gene_discretization(g_columns,z_scores,5),cell_discretization(c_columns,z_scores,6)],axis=1)\n",
    "discretized=pd.concat([features.iloc[:,:3], discretized],axis=1)\n",
    "\n",
    "# Data used for the model:                                                                                                                       \n",
    "xtrain = discretized.loc[xtrain.index.tolist(), :].copy()\n",
    "#xtrain = xtrain.drop('cp_type', axis=1)                                                                                                         \n",
    "ytrain = targets.loc[xtrain.index.tolist(), :].copy() #remains the same                                                                          \n",
    "# Data used for the predictions:                                                                                                                 \n",
    "xtest = discretized.loc[xtest.index.tolist(), :].copy()\n",
    "svc_model = MultipleColumns_model(xtrain, ytrain, ytrain.shape[1], SVC)\n",
    "from joblib import dump\n",
    "dump(svc_model, 'output/7i_model.joblib')\n",
    "#new dataframe for saving the predictions                                                                                                        \n",
    "proba_pred_SVC = pd.DataFrame(columns=ytest.columns)\n",
    "name_col = ytest.columns.tolist()\n",
    "for i in range(ytest.shape[1]):\n",
    "    proba_pred_SVC[name_col[i]] = svc_model[i].predict_proba(xtest)[:, 1]\n",
    "    print(i, end=' ', flush=True)\n",
    "proba_pred_SVC[\"sig_id\"]= xtest.index.tolist()\n",
    "proba_pred_SVC = proba_pred_SVC.set_index('sig_id')\n",
    "proba_pred_SVC.to_csv('output/7i_probas.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
